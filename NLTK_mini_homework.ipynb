{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Using NLTK\n",
    "The training data contains about 8,000 comments with corresponding stars(1 to 5). Assume that we're going to train a model to predict the star by the comment. In this homework, we're going to implement data preprocessing by using NLTK. The steps are shown below.\n",
    "<br>\n",
    "<li> Import the packages you need and read the csv file.\n",
    "<li> Turn each comment into a word bag. Remember the bag only contain verb and adjective, stop words and punctuations are excluded.\n",
    "<li> Turn the word bag into number using one-hot encoding. Each row represents the sample, and each column represent the word.\n",
    "<li> Finally, using the train_test_split function in sklearn.model_selection to split the data into training set and testing set. Then put the training set into the model.(This part of code is provided.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3223</td>\n",
       "      <td>2055</td>\n",
       "      <td>2533</td>\n",
       "      <td>Sometimes things happen, and when they do this...</td>\n",
       "      <td>2010/12/30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9938</td>\n",
       "      <td>4165</td>\n",
       "      <td>6371</td>\n",
       "      <td>I know Kerrie through my networking and we ben...</td>\n",
       "      <td>2011/4/26</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7123</td>\n",
       "      <td>869</td>\n",
       "      <td>4929</td>\n",
       "      <td>Love their pizza!!!\\r\\nVery fresh. Their canno...</td>\n",
       "      <td>2012/9/28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3601</td>\n",
       "      <td>1603</td>\n",
       "      <td>2789</td>\n",
       "      <td>Being from NJ I am always on the prowl for my ...</td>\n",
       "      <td>2009/6/7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3948</td>\n",
       "      <td>2347</td>\n",
       "      <td>1245</td>\n",
       "      <td>We have tried this spot a few times and each v...</td>\n",
       "      <td>2011/2/20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  business_id  user_id  \\\n",
       "0       3223         2055     2533   \n",
       "1       9938         4165     6371   \n",
       "2       7123          869     4929   \n",
       "3       3601         1603     2789   \n",
       "4       3948         2347     1245   \n",
       "\n",
       "                                                text        date  stars  \n",
       "0  Sometimes things happen, and when they do this...  2010/12/30      5  \n",
       "1  I know Kerrie through my networking and we ben...   2011/4/26      5  \n",
       "2  Love their pizza!!!\\r\\nVery fresh. Their canno...   2012/9/28      5  \n",
       "3  Being from NJ I am always on the prowl for my ...    2009/6/7      4  \n",
       "4  We have tried this spot a few times and each v...   2011/2/20      4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Write a function to turn all the comments into wordbag, and pick up verbs and adjectives only.\n",
    "<br>1.input the \"text\" column in df (i.e. df.text), and tokenize all the comments(nltk.word_tokenize() )\n",
    "<br>2. pick up all the stop words and punctuation (string.punctuation and nltk.corpus.stopwords.words('english')  )\n",
    "<br>3. pos_tag the remain words, and pick up lemmatized verbs and  lemmatized adjectives only.(nltk.pos_tag()  and wnl.lemmatize())\n",
    "<br>4. return a list which contains dictionaries, each dictionary is a comment, i.e.\n",
    "<br>[{'happen': 1, 'want': 1, 'take': 1, 'best': 1, 'nice': 1, 'find': 1},\n",
    " {'know': 1,\n",
    "  'kerrie': 2,\n",
    "  'benefit': 1,\n",
    "  'need': 3,\n",
    "  'plan': 1,\n",
    "  'remind': 1,\n",
    "1},\n",
    " {'love': 1, 'fresh': 1, 'good': 1, 'seem': 1, 'great': 1},\n",
    " {'hometown': 1,\n",
    "  'italian': 1,\n",
    "  'best': 1,\n",
    "  'pizza': 1,\n",
    "  'big': 1,}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_document(lis_text):\n",
    "    output = list()\n",
    "    for sentence in lis_text:\n",
    "        stopword = stopwords.words('english')\n",
    "        all_punc = [punc for punc in string.punctuation]\n",
    "        for punc in all_punc:\n",
    "            sentence=sentence.replace(punc,\" . \")\n",
    "        words=nltk.word_tokenize(sentence)\n",
    "        wordstosave=list()\n",
    "        for word, pos in pos_tag(words):\n",
    "            if (\".\" not in word and word not in stopword):\n",
    "                if pos.startswith(\"J\"):\n",
    "                    wordstosave.append(wnl.lemmatize(word, \"a\"))\n",
    "                elif pos.startswith(\"V\"):\n",
    "                    wordstosave.append(wnl.lemmatize(word, \"v\"))\n",
    "        wordbag = dict()\n",
    "        for word in wordstosave:\n",
    "            wordbag[word] = 1 if word not in wordbag else wordbag[word] + 1\n",
    "        output.append(wordbag)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Write a function to turn the bag of word into numeric numpy array by one-hot encoding method.\n",
    "<br>1. Input the list from the return of above function.\n",
    "<br>2. create a python set, called \"features\", containing all the word in all comments.  ex:{\"I\", \"have\", \"a\", \"dog\", \"cat\"}\n",
    "<br>3. create a nested list, called mat, containg the counts of word in each comment.  \n",
    "<br>ex:  [{\"I\":1, \"have\":1, \"a\":1, \"dog\":1}, {\"I\":1, \"have\":1, \"a\":1, \"cat\":1}] -->[[1,1,1,1,0], [1,1,1,0,1]]\n",
    "<br>4. put the nested into numpy.array() and return the array and \"features\" set as the function results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorize_mat(token_lis):\n",
    "    features = set()\n",
    "    for lines in token_lis:\n",
    "        for word in lines:\n",
    "            if word not in features: \n",
    "                features.add(word)\n",
    "    features = sorted(features)\n",
    "    mat = list()\n",
    "    for lines in token_lis:\n",
    "        count = [0] * len(features)\n",
    "        for word in lines:\n",
    "            count[features.index(word)] = lines[word]\n",
    "        mat.append(count)\n",
    "    return set(features),np.array(mat)\n",
    "features,one_hot_mat = vectorize_mat(tokenize_document(df.text))\n",
    "one_hot_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we choose Multinomial Naive Bayes Classifier as the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7997, 10173)\n",
      "Under MNB model, MSE and accuracy are 1.057 and 0.475, respectively.\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_lab, test_lab = train_test_split(csr_matrix(one_hot_mat), df.stars\n",
    "                                                              , train_size = 0.8, random_state = 123)\n",
    "MNB_model = MultinomialNB(alpha = 0.5)\n",
    "MNB_model.fit(train_data, train_lab)\n",
    "MSE = np.std(MNB_model.predict(test_data) - test_lab)\n",
    "ACC = MNB_model.score(test_data, test_lab)\n",
    "print(one_hot_mat.shape)\n",
    "print(\"Under MNB model, MSE and accuracy are %.3f and %.3f, respectively.\" % (MSE, ACC) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
